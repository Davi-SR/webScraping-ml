# ğŸ“Š Pipeline de Dados e Web Scraping do Mercado Livre

Este projeto Ã© um pipeline de dados ETL completo que extrai, em tempo real, dados de anÃºncios do Mercado Livre atravÃ©s de Web Scraping, processa e limpa essas informaÃ§Ãµes, e as carrega em um banco de dados PostgreSQL para futuras anÃ¡lises.

## ğŸ“œ DescriÃ§Ã£o

O objetivo deste projeto foi construir uma soluÃ§Ã£o de engenharia de dados do zero, simulando um cenÃ¡rio real onde os dados nÃ£o estÃ£o disponÃ­veis via API. O pipeline Ã© capaz de:

1.  Navegar pelas pÃ¡ginas de resultados de uma busca especÃ­fica no Mercado Livre.
2.  Extrair informaÃ§Ãµes relevantes de cada anÃºncio (tÃ­tulo e preÃ§o).
3.  Estruturar, limpar e transformar os dados brutos em um formato analÃ­tico e numÃ©rico usando a biblioteca Pandas.
4.  Carregar os dados tratados em um banco de dados relacional (PostgreSQL), prontos para serem consumidos por ferramentas de BI ou outras aplicaÃ§Ãµes.

## âœ¨ Funcionalidades

- **Web Scraping Multi-PÃ¡gina:** O robÃ´ navega automaticamente pela paginaÃ§Ã£o do site, coletando dados de todas as pÃ¡ginas de resultados.
- **ExtraÃ§Ã£o Robusta de Dados:** Utiliza `BeautifulSoup` para parsear o HTML e extrair os dados de interesse, mesmo com a complexidade da estrutura do site.
- **Limpeza e TransformaÃ§Ã£o:** Processamento dos dados com `Pandas` para converter preÃ§os em formato de texto (ex: "R$ 4.899") para um formato numÃ©rico e limpo.
- **PersistÃªncia de Dados:** Carrega os dados limpos em um banco de dados PostgreSQL, incluindo uma coluna `data_coleta` para rastreabilidade temporal.
- **PrÃ¡ticas de SeguranÃ§a:** Gerenciamento de credenciais do banco de dados de forma segura, utilizando variÃ¡veis de ambiente com um arquivo `.env`.

## ğŸ› ï¸ Tecnologias Utilizadas

Este projeto foi construÃ­do utilizando as seguintes tecnologias e bibliotecas:

<p align="left">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/Requests-232F3E?style=for-the-badge&logo=requests&logoColor=white" />
  <img src="https://img.shields.io/badge/Beautiful_Soup-000000?style=for-the-badge&logo=-&logoColor=white" />
  <img src="https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white" />
  <img src="https://img.shields.io/badge/SQLAlchemy-B22222?style=for-the-badge&logo=sqlalchemy&logoColor=white" />
</p>

## ğŸš€ Como Executar o Projeto

Para executar este projeto localmente, siga os passos abaixo:

**1. PrÃ©-requisitos:**
* Ter o Python 3.x instalado.
* Ter um servidor PostgreSQL instalado e rodando.

**2. Clone o RepositÃ³rio:**
```bash
git clone [URL-DO-SEU-REPOSITÃ“RIO-AQUI]
cd [NOME-DA-PASTA-DO-PROJETO]
````

**3. Crie e Ative o Ambiente Virtual:**

````Bash

# Crie o ambiente
python -m venv venv

# Ative o ambiente (Linux/Mac)
source venv/bin/activate

# Ative o ambiente (Windows)
.\venv\Scripts\activate

````
**4. Instale as DependÃªncias:**
````Bash
pip install pandas requests beautifulsoup4 sqlalchemy psycopg2-binary python-dotenv
````
**5. Configure as VariÃ¡veis de Ambiente:**

Crie um arquivo chamado .env na raiz do projeto.

Adicione a sua string de conexÃ£o do PostgreSQL a ele:
````Bash
DATABASE_URL="postgresql://seu_usuario:sua_senha@localhost:5432/seu_banco"
````

**6. Prepare o Banco de Dados:**

Conecte-se ao seu PostgreSQL.

Crie o banco de dados (se nÃ£o existir).

Crie a tabela para receber os dados. Exemplo:
````Bash
CREATE TABLE anuncios_ps5 (
    id SERIAL PRIMARY KEY,
    titulo TEXT,
    preco INTEGER,
    data_coleta TIMESTAMP
);
````
**7. Execute o Scraper:**
````Bash
python scraper.py
````
Ao final da execuÃ§Ã£o, os dados estarÃ£o na sua tabela do PostgreSQL e um arquivo CSV de backup serÃ¡ gerado.

## ğŸ“ Estrutura do Projeto
| | |
| :--- | :--- |
| ğŸ“„ `scraper.py` | ğŸ `requirements.txt` |
| ğŸ“¦ `load.py` | ğŸ›¡ï¸ `.gitignore` |
| ğŸ”‘ `.env` | ğŸ“– `README.md` |


Desenvolvido com entusiasmo por Davi Silva Ramos.
