# üìä Pipeline de Dados e Web Scraping do Mercado Livre

Este projeto √© um pipeline de dados ETL completo que extrai, em tempo real, dados de an√∫ncios do Mercado Livre atrav√©s de Web Scraping, processa e limpa essas informa√ß√µes, e as carrega em um banco de dados PostgreSQL para futuras an√°lises.

## üìú Descri√ß√£o

O objetivo deste projeto foi construir uma solu√ß√£o de engenharia de dados do zero, simulando um cen√°rio real onde os dados n√£o est√£o dispon√≠veis via API. O pipeline √© capaz de:

1.  Navegar pelas p√°ginas de resultados de uma busca espec√≠fica no Mercado Livre.
2.  Extrair informa√ß√µes relevantes de cada an√∫ncio (t√≠tulo e pre√ßo).
3.  Estruturar, limpar e transformar os dados brutos em um formato anal√≠tico e num√©rico usando a biblioteca Pandas.
4.  Carregar os dados tratados em um banco de dados relacional (PostgreSQL), prontos para serem consumidos por ferramentas de BI ou outras aplica√ß√µes.

## ‚ú® Funcionalidades

- **Web Scraping Multi-P√°gina:** O rob√¥ navega automaticamente pela pagina√ß√£o do site, coletando dados de todas as p√°ginas de resultados.
- **Extra√ß√£o Robusta de Dados:** Utiliza `BeautifulSoup` para parsear o HTML e extrair os dados de interesse, mesmo com a complexidade da estrutura do site.
- **Limpeza e Transforma√ß√£o:** Processamento dos dados com `Pandas` para converter pre√ßos em formato de texto (ex: "R$ 4.899") para um formato num√©rico e limpo.
- **Persist√™ncia de Dados:** Carrega os dados limpos em um banco de dados PostgreSQL, incluindo uma coluna `data_coleta` para rastreabilidade temporal.
- **Pr√°ticas de Seguran√ßa:** Gerenciamento de credenciais do banco de dados de forma segura, utilizando vari√°veis de ambiente com um arquivo `.env`.

## üõ†Ô∏è Tecnologias Utilizadas

Este projeto foi constru√≠do utilizando as seguintes tecnologias e bibliotecas:

<p align="left">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/Requests-232F3E?style=for-the-badge&logo=requests&logoColor=white" />
  <img src="https://img.shields.io/badge/Beautiful_Soup-000000?style=for-the-badge&logo=-&logoColor=white" />
  <img src="https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white" />
  <img src="https://img.shields.io/badge/SQLAlchemy-B22222?style=for-the-badge&logo=sqlalchemy&logoColor=white" />
</p>

## üöÄ Como Executar o Projeto

Para executar este projeto localmente, siga os passos abaixo:

**1. Pr√©-requisitos:**
* Ter o Python 3.x instalado.
* Ter um servidor PostgreSQL instalado e rodando.

**2. Clone o Reposit√≥rio:**
```bash
git clone [URL-DO-SEU-REPOSIT√ìRIO-AQUI]
cd [NOME-DA-PASTA-DO-PROJETO]
````

**3. Crie e Ative o Ambiente Virtual:**

````Bash

# Crie o ambiente
python -m venv venv

# Ative o ambiente (Linux/Mac)
source venv/bin/activate

# Ative o ambiente (Windows)
.\venv\Scripts\activate

````
**4. Instale as Depend√™ncias:**
````Bash
pip install pandas requests beautifulsoup4 sqlalchemy psycopg2-binary python-dotenv
````
**5. Configure as Vari√°veis de Ambiente:**

Crie um arquivo chamado .env na raiz do projeto.

Adicione a sua string de conex√£o do PostgreSQL a ele:
````Bash
DATABASE_URL="postgresql://seu_usuario:sua_senha@localhost:5432/seu_banco"
````

**6. Prepare o Banco de Dados:**

Conecte-se ao seu PostgreSQL.

Crie o banco de dados (se n√£o existir).

Crie a tabela para receber os dados. Exemplo:
````Bash
CREATE TABLE anuncios_ps5 (
    id SERIAL PRIMARY KEY,
    titulo TEXT,
    preco INTEGER,
    data_coleta TIMESTAMP
);
````
**7. Execute o Scraper:**
````Bash
python scraper.py
````
Ao final da execu√ß√£o, os dados estar√£o na sua tabela do PostgreSQL e um arquivo CSV de backup ser√° gerado.

## üìÅ Estrutura do Projeto
.
‚îú‚îÄ‚îÄ scraper.py         # Script principal que orquestra todo o processo de ETL
‚îú‚îÄ‚îÄ load.py            # M√≥dulo com a fun√ß√£o de carga para o PostgreSQL
‚îú‚îÄ‚îÄ .env               # Arquivo local com as credenciais (ignorado pelo Git)
‚îú‚îÄ‚îÄ .gitignore         # Arquivo que especifica o que o Git deve ignorar
‚îú‚îÄ‚îÄ requirements.txt   # Lista de depend√™ncias Python do projeto
‚îî‚îÄ‚îÄ README.md          # Esta documenta√ß√£o


Desenvolvido com entusiasmo por Davi Silva Ramos.
